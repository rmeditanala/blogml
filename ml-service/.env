# Environment variables for BlogML ML Service

# Server Configuration
PORT=8000
ENVIRONMENT=development

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Model Configuration
MODEL_CACHE_DIR=./models
MAX_CONCURRENT_REQUESTS=10

# Hugging Face Configuration
# Get your token from: https://huggingface.co/settings/tokens
# Required for using Hugging Face Inference API instead of local models
HUGGINGFACE_API_TOKEN=null
HF_TOKEN=null  # Legacy name for compatibility
HF_HOME=./models/huggingface

# Model Loading Configuration
# FORCE_LOCAL_MODELS=true  # Uncomment to force local model usage instead of API

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Performance
TORCH_DEVICE=auto  # auto, cpu, cuda
MAX_MEMORY_USAGE=0.8  # 80% of available memory